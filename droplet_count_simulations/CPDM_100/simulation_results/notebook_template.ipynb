{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# couldn't do full multiprocessing b/c each notebook was trying to use e.g. 71 threads\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from zipfile import BadZipfile\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulations.distributions import CPDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-watch",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "rate = 2\n",
    "entropy = 42\n",
    "concentration = 100.0\n",
    "number_samples = 1000\n",
    "number_simulations = 500\n",
    "simulation_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert simulation_number <= number_simulations\n",
    "seed_sequence = np.random.SeedSequence(entropy)\n",
    "seed = seed_sequence.spawn(number_simulations)[simulation_number-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_relative_abundances = [1e-4, 1e-3, 1e-2]\n",
    "\n",
    "relative_abundances = [relative_abundance * number\n",
    "                       for relative_abundance \n",
    "                       in base_relative_abundances\n",
    "                       for number in (1,2,5) \n",
    "                       for repeat in range(10)]\n",
    "\n",
    "relative_abundances += [1-sum(relative_abundances)]\n",
    "frequencies = np.array(relative_abundances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-compression",
   "metadata": {},
   "source": [
    "yes I am not vectorizing as much as I could here (I had an excuse for the CTPMHg but not now) but this code is easier to write/understand and ensure correctness.\n",
    "\n",
    "if I were to create production code that I knew/expected people would use downstream (as well as receive any credit or compensation for effort spent improving the code) I would look into better algorithms for vectorizing this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-elimination",
   "metadata": {},
   "source": [
    "## CPDM - Compound Poisson Dirichlet Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPDM_simulation(concentration, frequencies, rate, \n",
    "                      seed, number_samples):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    results = [CPDM(concentration, frequencies, rate, rng) for sample in range(number_samples)]\n",
    "    \n",
    "    results = [result.reshape((1,-1)) for result in results]\n",
    "    results = np.concatenate(results, axis=0)\n",
    "    # shape of results is now (number_droplets, number_strains)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettify = lambda integer: str(integer).zfill(len(str(number_simulations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filename = 'npzfiles/CPDM_results.{}.npz'.format(prettify(simulation_number))\n",
    "results_file = Path(results_filename)\n",
    "\n",
    "# simulation may have already ran successfully on previous attempt\n",
    "try:\n",
    "    np.load(results_filename)\n",
    "except (BadZipfile, FileNotFoundError): # file is corrupted or does not exist\n",
    "    results_file.unlink(missing_ok=True) # delete corrupted file if it exists\n",
    "    start_time = time.time()\n",
    "    results = CPDM_simulation(concentration=concentration,\n",
    "                    rate=rate, seed=seed, \n",
    "                    number_samples=number_samples,\n",
    "                    frequencies=frequencies)\n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    with open('notebook_logs/runtime.{}.log'.format(prettify(simulation_number)), 'a') as file_pointer:\n",
    "        # https://stackoverflow.com/a/775095/10634604\n",
    "        runtime_string = str(datetime.timedelta(seconds=runtime))\n",
    "        file_pointer.write('\\nRuntime was {} in Hours:Minutes:Seconds.\\n'.format(runtime_string))\n",
    "\n",
    "    # https://stackoverflow.com/a/35490226/10634604\n",
    "    # https://stackoverflow.com/a/273227/10634604\n",
    "    results_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(results_filename, droplets=results)\n",
    "            \n",
    "    # Maybe this will help prevent memory leaks? \n",
    "    # Honestly not sure what happens when using papermill with multiprocessing.\n",
    "    del(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
