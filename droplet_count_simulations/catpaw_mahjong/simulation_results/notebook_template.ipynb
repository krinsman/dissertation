{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6c356-f95d-45c7-8373-5c0ebd152a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc5211-476c-459d-a214-201f1397c0a3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "population_size = int(5e8)\n",
    "rate = 2\n",
    "entropy = 42\n",
    "number_samples = 1000\n",
    "number_simulations = 500\n",
    "simulation_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6020439-5650-4000-9e2e-52e63e514e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert simulation_number <= number_simulations\n",
    "seed_sequence = np.random.SeedSequence(entropy)\n",
    "seed = seed_sequence.spawn(number_simulations)[simulation_number-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10b7c3-3e4e-4e30-9642-29779fe4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_relative_abundances = [1e-4, 1e-3, 1e-2]\n",
    "\n",
    "relative_abundances = [relative_abundance * number\n",
    "                       for relative_abundance \n",
    "                       in base_relative_abundances\n",
    "                       for number in (1,2,5) \n",
    "                       for repeat in range(10)]\n",
    "\n",
    "relative_abundances += [1-sum(relative_abundances)]\n",
    "frequencies = np.array(relative_abundances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f959b0e-b76c-4fc0-8657-1d094d4934b9",
   "metadata": {},
   "source": [
    "## CTPMHg Simulation - Iterate over droplets, then over marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df89d2-fd29-42b9-8b0b-8676b6d1d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTPMHg_simulation_droplets_strains(population_size, rate, seed, number_samples, frequencies):\n",
    "    # probably doing a little bit too much implicit rounding here in general but... too lazy to change\n",
    "    sub_population_sizes = (population_size * frequencies).astype(int)\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    total_sample_sizes = rng.poisson(lam=rate, size=number_samples)\n",
    "\n",
    "    # seems like this variable is also only used for unit testing in this function\n",
    "    # although this unit test is more important b/c if it fails then sample wasn't\n",
    "    # actually from the truncated Poisson distribution so...\n",
    "    cumulative_sample_sizes = np.cumsum(total_sample_sizes)\n",
    "    try:\n",
    "        assert cumulative_sample_sizes[-1] <= population_size\n",
    "    except AssertionError as e:\n",
    "        raise NotImplementedError(e)\n",
    "\n",
    "    # seems like in this function I don't actually need this variable for algorithm\n",
    "    # just for like unit testing at the end of the function, that is what it seems to me\n",
    "    remaining_population_sizes = np.sum(sub_population_sizes) * np.ones(number_samples).astype(int)\n",
    "    remaining_population_sizes[1:] -= cumulative_sample_sizes[:-1]\n",
    "\n",
    "    remaining_sub_population_sizes = np.zeros((len(frequencies), number_samples)).astype(int)\n",
    "    remaining_sub_population_sizes[:,0] = sub_population_sizes\n",
    "\n",
    "    sample_sizes = np.zeros((len(frequencies), number_samples)).astype(int)\n",
    "\n",
    "    for d in range(number_samples-1):\n",
    "        droplet_d_sample = rng.multivariate_hypergeometric(\n",
    "                                            colors=remaining_sub_population_sizes[:,d],\n",
    "                                            nsample=total_sample_sizes[d],\n",
    "                                            method='marginals'\n",
    "                                            )\n",
    "        remaining_sub_population_sizes[:,d+1] = remaining_sub_population_sizes[:,d] - droplet_d_sample\n",
    "        sample_sizes[:,d] = droplet_d_sample\n",
    "        \n",
    "    droplet_d_sample = rng.multivariate_hypergeometric(\n",
    "                                        colors=remaining_sub_population_sizes[:,number_samples-1],\n",
    "                                        nsample=total_sample_sizes[number_samples-1],\n",
    "                                        method='marginals'\n",
    "                                        )\n",
    "    sample_sizes[:,number_samples-1] = droplet_d_sample\n",
    "\n",
    "    assert np.all(remaining_population_sizes == np.sum(remaining_sub_population_sizes, axis=0))\n",
    "    assert np.all(total_sample_sizes == np.sum(sample_sizes,axis=0))\n",
    "\n",
    "    return {\"pop_sizes\": remaining_sub_population_sizes, \"sample_sizes\": sample_sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bf808-1ec8-4ad0-87ce-87f6a48fc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettify = lambda integer: str(integer).zfill(len(str(number_simulations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c9096-8f8d-46eb-9e43-ed430f457441",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filename = 'npzfiles/CTPMHg_results.{}.npz'.format(prettify(simulation_number))\n",
    "results_file = Path(results_filename)\n",
    "\n",
    "if results_file.is_file():\n",
    "    # simulation already ran successfully on previous attempt\n",
    "    pass\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    results = CTPMHg_simulation_droplets_strains(population_size=population_size, \n",
    "                                                rate=rate, seed=seed, \n",
    "                                                number_samples=number_samples, \n",
    "                                                frequencies=frequencies)\n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    with open('notebook_logs/runtime.{}.log'.format(prettify(simulation_number)), 'a') as file_pointer:\n",
    "        # https://stackoverflow.com/a/775095/10634604\n",
    "        runtime_string = str(datetime.timedelta(seconds=runtime))\n",
    "        file_pointer.write('Runtime was {} in Hours:Minutes:Seconds.'.format(runtime_string))\n",
    "\n",
    "    np.savez_compressed(results_filename, **results)\n",
    "            \n",
    "    # Maybe this will help prevent memory leaks? \n",
    "    # Honestly not sure what happens when using papermill with multiprocessing.\n",
    "    del(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
