{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = \n",
    "number_droplets = 100000\n",
    "number_simulations = 100\n",
    "seed = 42\n",
    "number_last_completed_simulation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from simulations.utils import random_copy_numbers\n",
    "from simulations.parallel import dropletSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 11\n",
    "number_batches = 5\n",
    "results_dir_name = 'results' # if change this, don't end it in a `/`\n",
    "# or if change to end in `/`, edit definition of `base_simulation_filename`\n",
    "\n",
    "base_simulation_filename = results_dir_name + '/{}_strains.seed_{}.{}_droplets.iteration_{}.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sequence = np.random.SeedSequence(seed)\n",
    "Path(\"./\" + results_dir_name).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-liver",
   "metadata": {},
   "source": [
    "We can set `number_last_completed_simulation` to be the number of the last simulation (1-indexed) that was completed in the case that was disrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_last_completed_simulation > 0:\n",
    "    # have seed sequence go through `number_last_completed_simulation` spawn keys\n",
    "    # so that next simulation starts at the correct spawn key,\n",
    "    # namely the `number_last_completed_simulation + 1`th\n",
    "    seed_sequence.spawn(number_last_completed_simulation)\n",
    "    # not necessary though if we're not resuming a previously interrupted simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for simulation_number in range(number_last_completed_simulation, number_simulations):\n",
    "    # Python is 0-indexed, so the `number_last_completed_simulation +1`th simulation\n",
    "    # has the index `number_last_completed_simulation`\n",
    "    simulation_seed = seed_sequence.spawn(1)[0]\n",
    "    rng = np.random.default_rng(simulation_seed)\n",
    "\n",
    "    frequency_vector = pct*np.ones(size)\n",
    "    frequency_vector[-1] = (1 - np.sum(frequency_vector[:-1]))\n",
    "    assert np.sum(frequency_vector) == 1\n",
    "    \n",
    "    A = 2*(rng.random((size,size)) - 0.5)\n",
    "    A *= rng.integers(low=0, high=2, size=A.shape) # make interactions more sparse, so scientifically more interesting/plausible\n",
    "    beta = rng.random(size)\n",
    "\n",
    "    simulation = dropletSimulation(number_species=size, number_droplets=number_droplets, \n",
    "                   number_batches=number_batches, copy_numbers=random_copy_numbers(size, rng), \n",
    "                   frequency_vector=frequency_vector, glv_interaction_coefficients=A, \n",
    "                   glv_baserate_coefficients=beta, noise_scale=5, seed=simulation_seed,\n",
    "                   timestep=0.01, batch_window=2, merging_error=.1) # NON-ZERO MERGING ERROR\n",
    "\n",
    "    simulation.run_simulation()\n",
    "    # Not necessary for phenopath\n",
    "    # simulation.group_droplets()\n",
    "    # Not a big time sink though for small number of species\n",
    "\n",
    "    truth = simulation.glv_interaction_coefficients\n",
    "\n",
    "    ### Save 'Cells' Results\n",
    "    # NumPy doesn't offer enough control over reshaping (e.g. specifying which axes should be mapped to which axes)\n",
    "    cell_counts = np.array([simulation.cells[...,i] for i in range(simulation.cells.shape[-1])])\n",
    "    # So we have to do this somewhat 'manually' to ensure right result: both 'C' and 'F' give wrong results\n",
    "    cell_counts = cell_counts.reshape((number_batches*number_droplets, size))\n",
    "\n",
    "    cells_non_zero = (cell_counts != 0)\n",
    "    cell_init_vectors = cells_non_zero.astype(int)\n",
    "    # Return 0 for 0 otherwise log(x) if x > 0\n",
    "    cell_log_counts = np.log(cell_counts + ~cells_non_zero)\n",
    "\n",
    "    # Sanity check that the weird reshaping does what it's supposed to do\n",
    "    # too often I treat reshaping like a black box and assume it works\n",
    "    for i in range(simulation.cells.shape[-1]):\n",
    "        np.all(cell_counts[i*simulation.cells.shape[0]:(i+1)*simulation.cells.shape[0]] == simulation.cells[:,:,i])\n",
    "\n",
    "    ### Save 'Reads' Results\n",
    "    read_counts = np.array([simulation.reads[...,i] for i in range(simulation.reads.shape[-1])])\n",
    "    read_counts = read_counts.reshape((number_batches*simulation.reads.shape[0], size))\n",
    "\n",
    "    reads_non_zero = (read_counts != 0)\n",
    "    read_init_vectors = reads_non_zero.astype(int)\n",
    "    read_log_counts = np.log(read_counts + ~reads_non_zero)\n",
    "\n",
    "    for i in range(simulation.reads.shape[-1]):\n",
    "        np.all(read_counts[i*simulation.reads.shape[0]:(i+1)*simulation.reads.shape[0]] == simulation.reads[:,:,i])\n",
    "\n",
    "    # Save intermediate results in case there's a crash, so can resume progress by using the\n",
    "    # `number_last_completed_simulation` variable defined at top of notebook above\n",
    "    simulation_filename = base_simulation_filename.format(\n",
    "        size,seed,number_droplets,simulation_number+1)\n",
    "        \n",
    "    np.savez_compressed(simulation_filename, \n",
    "                cell_log_counts=cell_log_counts,\n",
    "                read_log_counts = read_log_counts,\n",
    "                cell_init_vectors = cell_init_vectors,\n",
    "                read_init_vectors = read_init_vectors,\n",
    "                        truth=truth\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-divide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
