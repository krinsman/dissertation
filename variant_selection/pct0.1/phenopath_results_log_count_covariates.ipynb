{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contained-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"phenopath\")\n",
    "library(\"reticulate\")\n",
    "np <- import(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wooden-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finite-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenopath_defaults <- function(observations, covariates, ...) {\n",
    "    # suppressWarnings because I am well aware that it hasn't converged\n",
    "    return(suppressWarnings(phenopath(observations, covariates, model_mu=TRUE, \n",
    "                                      maxiter=50, thin=10, verbose=FALSE, ...)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "committed-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman <- function(x,y){return(cor(x,y,method='spearman'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clear-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 11\n",
    "seed = 42\n",
    "number_droplets = 100000\n",
    "number_batches = 5\n",
    "results_dirname = 'results'\n",
    "\n",
    "base_filename = paste(results_dirname, '/', size, '_strains.seed_', \n",
    "                      seed, '.', format(number_droplets, scientific=FALSE), '_droplets.iteration_',\n",
    "                      '#', '.npz', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decimal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results <- function(phenopath_results, true_times) {\n",
    "    uncensored_results <- interaction_effects(phenopath_results)\n",
    "    censored_results <- significant_interactions(phenopath_results) * uncensored_results\n",
    "    pearson <- abs(cor(true_times, trajectory(phenopath_results))) # same level of support if pseudotimes are flipped\n",
    "    spearman <- abs(spearman(true_times, trajectory(phenopath_results)))\n",
    "    \n",
    "    results <- list(\"uncensored_results\" = uncensored_results, \n",
    "                   \"censored_results\" = censored_results,\n",
    "                   \"pearson\" = pearson,\n",
    "                   \"spearman\" = spearman)\n",
    "    return(results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_filename <- function(base_dir, scaling, iteration_number) {\n",
    "    iteration_filename = paste('iteration_', iteration_number, '.npz', sep='')\n",
    "    results_dir = file.path(paste(base_dir, '/', scaling, sep=''))\n",
    "    results_filename = file.path(paste(results_dir, '/', iteration_filename, sep=''))\n",
    "    return(results_filename)\n",
    "}\n",
    "\n",
    "save_results <- function(results_filename, results) {\n",
    "    np$savez_compressed(results_filename,\n",
    "    uncensored_results = results$uncensored_results,\n",
    "    censored_results = results$censored_results,\n",
    "    pearson = results$pearson,\n",
    "    spearman = results$spearman)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspected-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dir = 'phenopath_results'\n",
    "if (!dir.exists(all_results_dir)) {dir.create(all_results_dir)}\n",
    "\n",
    "log_counts_cov_results_dir = file.path(paste(all_results_dir, '/', 'log_count_covariates', sep=''))\n",
    "if (!dir.exists(log_counts_cov_results_dir)) {dir.create(log_counts_cov_results_dir)}\n",
    "\n",
    "for (subdirectory in list.files(path=all_results_dir, full.names=T)) {\n",
    "    scaled_results_dir = file.path(paste(subdirectory, '/', 'scaled', sep=''))\n",
    "    if (!dir.exists(scaled_results_dir)) {dir.create(scaled_results_dir)}\n",
    "    \n",
    "    unscaled_results_dir = file.path(paste(subdirectory, '/', 'unscaled', sep=''))\n",
    "    if (!dir.exists(unscaled_results_dir)) {dir.create(unscaled_results_dir)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-diagnosis",
   "metadata": {},
   "source": [
    "loop through the iterations of stored results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suffering-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very bad naughty code that uses lots of global variables\n",
    "# this is a self-contained notebook however and not a software library.\n",
    "# I don't want to rewrite the function and the function calls to unnecessarily be\n",
    "# much longer when scope rules automatically do the right thing.\n",
    "lapply_input <- function(iteration_number){\n",
    "    \n",
    "    filename = gsub(\"#\", iteration_number, base_filename)\n",
    "    npzfile = np$load(filename)\n",
    "\n",
    "    read_log_counts = npzfile[[\"read_log_counts\"]]\n",
    "    \n",
    "    merged_droplets_per_batch <- dim(read_log_counts)[1]/number_batches\n",
    "    true_times = c()\n",
    "    for (i in 1:number_batches) {true_times <- append(true_times, rep(i, merged_droplets_per_batch))}\n",
    "    \n",
    "    start_time <- proc.time()\n",
    "    log_counts_scaled <- phenopath_defaults(read_log_counts, read_log_counts, scale_y=TRUE)\n",
    "    results <- get_results(log_counts_scaled, true_times)\n",
    "    save_results(get_results_filename(log_counts_cov_results_dir, 'scaled', iteration_number), results)\n",
    "    run_time <- proc.time() - start_time; print(run_time)\n",
    "    \n",
    "    start_time <- proc.time()\n",
    "    log_counts_unscaled <- phenopath_defaults(read_log_counts, read_log_counts, scale_y=FALSE)\n",
    "    results <- get_results(log_counts_unscaled, true_times)\n",
    "    save_results(get_results_filename(log_counts_cov_results_dir, 'unscaled', iteration_number), results)\n",
    "    run_time <- proc.time() - start_time; print(run_time)\n",
    "    \n",
    "    # this is supposed to be an embarrassingly parallel for loop, so memory usage should not change with number of iterations\n",
    "    # but system monitor shows memory usage continually increasing. Hadley Wickham seems to have said that calling `gc`\n",
    "    # manually for garbage collection should never be necessary, but honestly at this point I don't trust R so...\n",
    "    gc()\n",
    "    \n",
    "    # controversial stylistically but consistent with Python style and since most programming is done\n",
    "    # in Python, from a practical perspective it's better for me to use stylistic conventions that also work in Python.\n",
    "    return(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "lapply(1:71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "documented-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "lapply(72:100, lapply_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
